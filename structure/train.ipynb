{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77569f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from structure.loaddate_aduc import create_dual_backbone_datasets, dual_backbone_collate_fn\n",
    "from structure.model import DualBackboneTimeLapseClassifier\n",
    "\n",
    "def train_dual_backbone_model():\n",
    "    config = {\n",
    "        'root_dir': 'D:/stroke/embryo/vin_embryov2/',\n",
    "        'num_classes': 2,\n",
    "        'context_size': 5,\n",
    "        'reference_size': 3,\n",
    "        'batch_size': 8,\n",
    "        'learning_rate': 1e-4,\n",
    "        'num_epochs': 50,\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        'sampling_strategy': 'temporal_split',  # or 'uniform', 'random'\n",
    "    }\n",
    "    \n",
    "    print(f\"Using device: {config['device']}\")\n",
    "    \n",
    "    train_dataset, test_dataset = create_dual_backbone_datasets(\n",
    "        root_dir=config['root_dir'],\n",
    "        context_size=config['context_size'],\n",
    "        reference_size=config['reference_size'],\n",
    "        sampling_strategy=config['sampling_strategy']\n",
    "    )\n",
    "    \n",
    "    print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        collate_fn=dual_backbone_collate_fn,\n",
    "        num_workers=4,\n",
    "        pin_memory=True if config['device'] == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        collate_fn=dual_backbone_collate_fn,\n",
    "        num_workers=4,\n",
    "        pin_memory=True if config['device'] == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    model = DualBackboneTimeLapseClassifier(\n",
    "        num_classes=config['num_classes'],\n",
    "        context_size=config['context_size'],\n",
    "        reference_size=config['reference_size'],\n",
    "        context_encoder=\"efficientnet-b0\",\n",
    "        reference_encoder=\"efficientnet-b0\",\n",
    "        context_encoding_size=512,\n",
    "        reference_encoding_size=512,\n",
    "        mha_num_attention_heads=8,\n",
    "        mha_num_attention_layers=4,\n",
    "        dropout_rate=0.1\n",
    "    ).to(config['device'])\n",
    "    \n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]} [Train]')\n",
    "        for batch_idx, (context_frames, reference_frames, labels) in enumerate(train_pbar):\n",
    "            context_frames = context_frames.to(config['device'])\n",
    "            reference_frames = reference_frames.to(config['device'])\n",
    "            labels = labels.to(config['device'])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(context_frames, reference_frames)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*train_correct/train_total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        epoch_train_loss = train_loss / len(train_loader)\n",
    "        epoch_train_acc = 100. * train_correct / train_total\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracies.append(epoch_train_acc)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(test_loader, desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]} [Val]')\n",
    "            for context_frames, reference_frames, labels in val_pbar:\n",
    "                context_frames = context_frames.to(config['device'])\n",
    "                reference_frames = reference_frames.to(config['device'])\n",
    "                labels = labels.to(config['device'])\n",
    "                \n",
    "                outputs = model(context_frames, reference_frames)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                val_pbar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'Acc': f'{100.*val_correct/val_total:.2f}%'\n",
    "                })\n",
    "        \n",
    "        epoch_val_loss = val_loss / len(test_loader)\n",
    "        epoch_val_acc = 100. * val_correct / val_total\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(epoch_val_acc)\n",
    "        \n",
    "        scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"New best validation accuracy: {best_val_acc:.2f}%\")\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{config[\"num_epochs\"]}:')\n",
    "        print(f'  Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%')\n",
    "        print(f'  Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%')\n",
    "        print(f'  Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        print('-' * 60)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(\"\\nDetailed Classification Report:\")\n",
    "            print(classification_report(all_labels, all_predictions, \n",
    "                                      target_names=['Normal', 'Abnormal']))\n",
    "            print(\"\\nConfusion Matrix:\")\n",
    "            print(confusion_matrix(all_labels, all_predictions))\n",
    "            print('-' * 60)\n",
    "    \n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"\\nLoaded best model with validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    model.eval()\n",
    "    final_predictions = []\n",
    "    final_labels = []\n",
    "    final_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for context_frames, reference_frames, labels in tqdm(test_loader, desc='Final Evaluation'):\n",
    "            context_frames = context_frames.to(config['device'])\n",
    "            reference_frames = reference_frames.to(config['device'])\n",
    "            \n",
    "            probs = model.predict(context_frames, reference_frames)\n",
    "            predictions = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            final_predictions.extend(predictions.cpu().numpy())\n",
    "            final_labels.extend(labels.numpy())\n",
    "            final_probabilities.extend(probs.cpu().numpy())\n",
    "    \n",
    "    final_accuracy = accuracy_score(final_labels, final_predictions)\n",
    "    print(f\"\\nFinal Test Accuracy: {final_accuracy*100:.2f}%\")\n",
    "    print(\"\\nFinal Classification Report:\")\n",
    "    print(classification_report(final_labels, final_predictions, \n",
    "                              target_names=['Normal', 'Abnormal']))\n",
    "    print(\"\\nFinal Confusion Matrix:\")\n",
    "    print(confusion_matrix(final_labels, final_predictions))\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': best_model_state,\n",
    "        'config': config,\n",
    "        'train_losses': train_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'final_test_acc': final_accuracy\n",
    "    }, 'dual_backbone_best_model.pth')\n",
    "    \n",
    "    print(\"\\nModel saved as 'dual_backbone_best_model.pth'\")\n",
    "    \n",
    "    return model, {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'final_test_acc': final_accuracy\n",
    "    }\n",
    "\n",
    "\n",
    "def load_and_evaluate_model(model_path, test_dataset):\n",
    "    checkpoint = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    config = checkpoint['config']\n",
    "    \n",
    "    model = DualBackboneTimeLapseClassifier(\n",
    "        num_classes=config['num_classes'],\n",
    "        context_size=config['context_size'],\n",
    "        reference_size=config['reference_size']\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Loaded model with best validation accuracy: {checkpoint['best_val_acc']:.2f}%\")\n",
    "    print(f\"Final test accuracy from training: {checkpoint['final_test_acc']*100:.2f}%\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, history = train_dual_backbone_model()\n",
    "    \n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history['train_losses'], label='Train Loss')\n",
    "        plt.plot(history['val_losses'], label='Val Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Training and Validation Loss')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history['train_accuracies'], label='Train Acc')\n",
    "        plt.plot(history['val_accuracies'], label='Val Acc')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.legend()\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_curves.png')\n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not available. Skipping plot generation.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
